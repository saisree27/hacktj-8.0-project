{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0991cea5b64b9c8f1a5e529adc6e98b9f4130bd9227063c4718405cc81474a8af",
   "display_name": "Python 3.8.5 64-bit ('week1': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_midi(file):\n",
    "    \n",
    "    print(\"Loading Music File:\",file)\n",
    "    \n",
    "    notes=[]\n",
    "    notes_to_parse = None\n",
    "    \n",
    "    #parsing a midi file\n",
    "    midi = converter.parse(file)\n",
    "  \n",
    "    #grouping based on different instruments\n",
    "    s2 = instrument.partitionByInstrument(midi)\n",
    "\n",
    "    #Looping over all the instruments\n",
    "    for part in s2.parts:\n",
    "    \n",
    "        #select elements of only piano\n",
    "        if 'Piano' in str(part): \n",
    "        \n",
    "            notes_to_parse = part.recurse() \n",
    "      \n",
    "            #finding whether a particular element is note or a chord\n",
    "            for element in notes_to_parse:\n",
    "                \n",
    "                #note\n",
    "                if isinstance(element, note.Note):\n",
    "                    notes.append(str(element.pitch))\n",
    "                \n",
    "                #chord\n",
    "                elif isinstance(element, chord.Chord):\n",
    "                    notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "    return np.array(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading Music File: midi_samples/schumm-1.mid\n",
      "Loading Music File: midi_samples/schumm-2.mid\n",
      "Loading Music File: midi_samples/schub_d960_4.mid\n",
      "Loading Music File: midi_samples/schumm-3.mid\n",
      "Loading Music File: midi_samples/schub_d960_1.mid\n",
      "Loading Music File: midi_samples/schumm-6.mid\n",
      "Loading Music File: midi_samples/schumm-4.mid\n",
      "Loading Music File: midi_samples/schub_d960_2.mid\n",
      "Loading Music File: midi_samples/schub_d960_3.mid\n",
      "Loading Music File: midi_samples/schumm-5.mid\n",
      "Loading Music File: midi_samples/schuim-4.mid\n",
      "Loading Music File: midi_samples/schuim-1.mid\n",
      "Loading Music File: midi_samples/schuim-3.mid\n",
      "Loading Music File: midi_samples/schuim-2.mid\n",
      "Loading Music File: midi_samples/schubert_D850_4.mid\n",
      "Loading Music File: midi_samples/schubert_D935_4.mid\n",
      "Loading Music File: midi_samples/schub_d760_4.mid\n",
      "Loading Music File: midi_samples/schubert_D850_1.mid\n",
      "Loading Music File: midi_samples/schubert_D935_1.mid\n",
      "Loading Music File: midi_samples/schub_d760_1.mid\n",
      "Loading Music File: midi_samples/schubert_D850_2.mid\n",
      "Loading Music File: midi_samples/schub_d760_3.mid\n",
      "Loading Music File: midi_samples/schubert_D935_2.mid\n",
      "Loading Music File: midi_samples/schubert_D935_3.mid\n",
      "Loading Music File: midi_samples/schubert_D850_3.mid\n",
      "Loading Music File: midi_samples/schub_d760_2.mid\n",
      "Loading Music File: midi_samples/schu_143_2.mid\n",
      "Loading Music File: midi_samples/schu_143_3.mid\n",
      "Loading Music File: midi_samples/schu_143_1.mid\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#Array Processing\n",
    "import numpy as np\n",
    "\n",
    "#specify the path\n",
    "path='midi_samples/'\n",
    "\n",
    "#read all the filenames\n",
    "files=[i for i in os.listdir(path) if i.endswith(\".mid\")]\n",
    "\n",
    "#reading each midi file\n",
    "notes_array = np.array([read_midi(path+i) for i in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "308\n"
     ]
    }
   ],
   "source": [
    "#converting 2D array into 1D array\n",
    "notes_ = [element for note_ in notes_array for element in note_]\n",
    "\n",
    "#No. of unique notes\n",
    "unique_notes = list(set(notes_))\n",
    "print(len(unique_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([186.,  46.,  27.,  10.,   4.,   6.,   6.,  12.,   8.,   3.]),\n",
       " array([1.0000e+00, 1.7290e+02, 3.4480e+02, 5.1670e+02, 6.8860e+02,\n",
       "        8.6050e+02, 1.0324e+03, 1.2043e+03, 1.3762e+03, 1.5481e+03,\n",
       "        1.7200e+03]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "metadata": {},
     "execution_count": 55
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 360x360 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "image/png": {
       "width": 324,
       "height": 302
      },
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "#importing library\n",
    "from collections import Counter\n",
    "\n",
    "#computing frequency of each note\n",
    "freq = dict(Counter(notes_))\n",
    "\n",
    "#library for visualiation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#consider only the frequencies\n",
    "no=[count for _,count in freq.items()]\n",
    "\n",
    "#set the figure size\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "#plot\n",
    "plt.hist(no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "173\n"
     ]
    }
   ],
   "source": [
    "frequent_notes = [note_ for note_, count in freq.items() if count>=50]\n",
    "print(len(frequent_notes))\n",
    "\n",
    "new_music=[]\n",
    "\n",
    "for notes in notes_array:\n",
    "    temp=[]\n",
    "    for note_ in notes:\n",
    "        if note_ in frequent_notes:\n",
    "            temp.append(note_)            \n",
    "    new_music.append(temp)\n",
    "    \n",
    "new_music = np.array(new_music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_timesteps = 32\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for note_ in new_music:\n",
    "    for i in range(0, len(note_) - no_of_timesteps, 1):\n",
    "        \n",
    "        #preparing input and output sequences\n",
    "        input_ = note_[i:i + no_of_timesteps]\n",
    "        output = note_[i + no_of_timesteps]\n",
    "        \n",
    "        x.append(input_)\n",
    "        y.append(output)\n",
    "        \n",
    "x=np.array(x)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_x = list(set(x.ravel()))\n",
    "x_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_x))\n",
    "\n",
    "#preparing input sequences\n",
    "x_seq=[]\n",
    "for i in x:\n",
    "    temp=[]\n",
    "    for j in i:\n",
    "        #assigning unique integer to every note\n",
    "        temp.append(x_note_to_int[j])\n",
    "    x_seq.append(temp)\n",
    "    \n",
    "x_seq = np.array(x_seq)\n",
    "\n",
    "unique_y = list(set(y))\n",
    "y_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_y)) \n",
    "y_seq=np.array([y_note_to_int[i] for i in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(x_seq,y_seq,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm():\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(128,return_sequences=True))\n",
    "  model.add(LSTM(128))\n",
    "  model.add(Dense(256))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Dense(n_vocab))\n",
    "  model.add(Activation('softmax'))\n",
    "  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 32, 100)           17300     \n_________________________________________________________________\nconv1d (Conv1D)              (None, 32, 64)            19264     \n_________________________________________________________________\ndropout (Dropout)            (None, 32, 64)            0         \n_________________________________________________________________\nmax_pooling1d (MaxPooling1D) (None, 16, 64)            0         \n_________________________________________________________________\nconv1d_1 (Conv1D)            (None, 16, 128)           24704     \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 16, 128)           0         \n_________________________________________________________________\nmax_pooling1d_1 (MaxPooling1 (None, 8, 128)            0         \n_________________________________________________________________\nconv1d_2 (Conv1D)            (None, 8, 256)            98560     \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 8, 256)            0         \n_________________________________________________________________\nmax_pooling1d_2 (MaxPooling1 (None, 4, 256)            0         \n_________________________________________________________________\nglobal_max_pooling1d (Global (None, 256)               0         \n_________________________________________________________________\ndense (Dense)                (None, 256)               65792     \n_________________________________________________________________\ndense_1 (Dense)              (None, 173)               44461     \n=================================================================\nTotal params: 270,081\nTrainable params: 270,081\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.callbacks import *\n",
    "import keras.backend as K\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "    \n",
    "#embedding layer\n",
    "model.add(Embedding(len(unique_x), 100, input_length=32,trainable=True)) \n",
    "\n",
    "model.add(Conv1D(64,3, padding='causal',activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "    \n",
    "model.add(Conv1D(128,3,activation='relu',dilation_rate=2,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "\n",
    "model.add(Conv1D(256,3,activation='relu',dilation_rate=4,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "          \n",
    "#model.add(Conv1D(256,5,activation='relu'))    \n",
    "model.add(GlobalMaxPool1D())\n",
    "    \n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(unique_y), activation='softmax'))\n",
    "    \n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "503/503 [==============================] - 14s 27ms/step - loss: 4.5733 - val_loss: 4.0010\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.00103, saving model to best_model.h5\n",
      "Epoch 2/50\n",
      "503/503 [==============================] - 12s 24ms/step - loss: 3.8010 - val_loss: 3.7844\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.00103 to 3.78439, saving model to best_model.h5\n",
      "Epoch 3/50\n",
      "503/503 [==============================] - 12s 24ms/step - loss: 3.6045 - val_loss: 3.6338\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.78439 to 3.63376, saving model to best_model.h5\n",
      "Epoch 4/50\n",
      "503/503 [==============================] - 12s 24ms/step - loss: 3.4581 - val_loss: 3.5200\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.63376 to 3.51998, saving model to best_model.h5\n",
      "Epoch 5/50\n",
      "503/503 [==============================] - 12s 25ms/step - loss: 3.3554 - val_loss: 3.4906\n",
      "\n",
      "Epoch 00005: val_loss improved from 3.51998 to 3.49064, saving model to best_model.h5\n",
      "Epoch 6/50\n",
      "503/503 [==============================] - 13s 25ms/step - loss: 3.2698 - val_loss: 3.4032\n",
      "\n",
      "Epoch 00006: val_loss improved from 3.49064 to 3.40319, saving model to best_model.h5\n",
      "Epoch 7/50\n",
      "503/503 [==============================] - 13s 26ms/step - loss: 3.2065 - val_loss: 3.3777\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.40319 to 3.37773, saving model to best_model.h5\n",
      "Epoch 8/50\n",
      "503/503 [==============================] - 13s 25ms/step - loss: 3.1522 - val_loss: 3.2900\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.37773 to 3.28999, saving model to best_model.h5\n",
      "Epoch 9/50\n",
      "503/503 [==============================] - 14s 28ms/step - loss: 3.0874 - val_loss: 3.2802\n",
      "\n",
      "Epoch 00009: val_loss improved from 3.28999 to 3.28016, saving model to best_model.h5\n",
      "Epoch 10/50\n",
      "503/503 [==============================] - 15s 29ms/step - loss: 3.0358 - val_loss: 3.2221\n",
      "\n",
      "Epoch 00010: val_loss improved from 3.28016 to 3.22209, saving model to best_model.h5\n",
      "Epoch 11/50\n",
      "503/503 [==============================] - 17s 34ms/step - loss: 2.9824 - val_loss: 3.2056\n",
      "\n",
      "Epoch 00011: val_loss improved from 3.22209 to 3.20556, saving model to best_model.h5\n",
      "Epoch 12/50\n",
      "503/503 [==============================] - 16s 32ms/step - loss: 2.9498 - val_loss: 3.1778\n",
      "\n",
      "Epoch 00012: val_loss improved from 3.20556 to 3.17777, saving model to best_model.h5\n",
      "Epoch 13/50\n",
      "503/503 [==============================] - 14s 28ms/step - loss: 2.9226 - val_loss: 3.1511\n",
      "\n",
      "Epoch 00013: val_loss improved from 3.17777 to 3.15108, saving model to best_model.h5\n",
      "Epoch 14/50\n",
      "503/503 [==============================] - 16s 32ms/step - loss: 2.8755 - val_loss: 3.1230\n",
      "\n",
      "Epoch 00014: val_loss improved from 3.15108 to 3.12302, saving model to best_model.h5\n",
      "Epoch 15/50\n",
      "503/503 [==============================] - 15s 29ms/step - loss: 2.8521 - val_loss: 3.1091\n",
      "\n",
      "Epoch 00015: val_loss improved from 3.12302 to 3.10911, saving model to best_model.h5\n",
      "Epoch 16/50\n",
      "503/503 [==============================] - 15s 29ms/step - loss: 2.8170 - val_loss: 3.0857\n",
      "\n",
      "Epoch 00016: val_loss improved from 3.10911 to 3.08568, saving model to best_model.h5\n",
      "Epoch 17/50\n",
      "503/503 [==============================] - 15s 30ms/step - loss: 2.7863 - val_loss: 3.0755\n",
      "\n",
      "Epoch 00017: val_loss improved from 3.08568 to 3.07548, saving model to best_model.h5\n",
      "Epoch 18/50\n",
      "503/503 [==============================] - 17s 33ms/step - loss: 2.7721 - val_loss: 3.0673\n",
      "\n",
      "Epoch 00018: val_loss improved from 3.07548 to 3.06729, saving model to best_model.h5\n",
      "Epoch 19/50\n",
      "503/503 [==============================] - 15s 30ms/step - loss: 2.7505 - val_loss: 3.0303\n",
      "\n",
      "Epoch 00019: val_loss improved from 3.06729 to 3.03031, saving model to best_model.h5\n",
      "Epoch 20/50\n",
      "503/503 [==============================] - 15s 29ms/step - loss: 2.7295 - val_loss: 3.0275\n",
      "\n",
      "Epoch 00020: val_loss improved from 3.03031 to 3.02753, saving model to best_model.h5\n",
      "Epoch 21/50\n",
      "503/503 [==============================] - 14s 28ms/step - loss: 2.7153 - val_loss: 3.0137\n",
      "\n",
      "Epoch 00021: val_loss improved from 3.02753 to 3.01372, saving model to best_model.h5\n",
      "Epoch 22/50\n",
      "503/503 [==============================] - 14s 28ms/step - loss: 2.6949 - val_loss: 2.9869\n",
      "\n",
      "Epoch 00022: val_loss improved from 3.01372 to 2.98691, saving model to best_model.h5\n",
      "Epoch 23/50\n",
      "503/503 [==============================] - 15s 30ms/step - loss: 2.6702 - val_loss: 2.9856\n",
      "\n",
      "Epoch 00023: val_loss improved from 2.98691 to 2.98563, saving model to best_model.h5\n",
      "Epoch 24/50\n",
      "503/503 [==============================] - 14s 29ms/step - loss: 2.6592 - val_loss: 2.9622\n",
      "\n",
      "Epoch 00024: val_loss improved from 2.98563 to 2.96216, saving model to best_model.h5\n",
      "Epoch 25/50\n",
      "503/503 [==============================] - 18s 36ms/step - loss: 2.6473 - val_loss: 2.9391\n",
      "\n",
      "Epoch 00025: val_loss improved from 2.96216 to 2.93908, saving model to best_model.h5\n",
      "Epoch 26/50\n",
      "503/503 [==============================] - 15s 29ms/step - loss: 2.6298 - val_loss: 2.9612\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.93908\n",
      "Epoch 27/50\n",
      "503/503 [==============================] - 14s 28ms/step - loss: 2.6106 - val_loss: 2.9407\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2.93908\n",
      "Epoch 28/50\n",
      "503/503 [==============================] - 14s 27ms/step - loss: 2.5979 - val_loss: 2.9458\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2.93908\n",
      "Epoch 29/50\n",
      "503/503 [==============================] - 14s 29ms/step - loss: 2.5846 - val_loss: 2.9322\n",
      "\n",
      "Epoch 00029: val_loss improved from 2.93908 to 2.93220, saving model to best_model.h5\n",
      "Epoch 30/50\n",
      "503/503 [==============================] - 15s 30ms/step - loss: 2.5814 - val_loss: 2.9283\n",
      "\n",
      "Epoch 00030: val_loss improved from 2.93220 to 2.92829, saving model to best_model.h5\n",
      "Epoch 31/50\n",
      "503/503 [==============================] - 14s 29ms/step - loss: 2.5653 - val_loss: 2.9153\n",
      "\n",
      "Epoch 00031: val_loss improved from 2.92829 to 2.91526, saving model to best_model.h5\n",
      "Epoch 32/50\n",
      "503/503 [==============================] - 14s 28ms/step - loss: 2.5498 - val_loss: 2.9099\n",
      "\n",
      "Epoch 00032: val_loss improved from 2.91526 to 2.90991, saving model to best_model.h5\n",
      "Epoch 33/50\n",
      "503/503 [==============================] - 15s 29ms/step - loss: 2.5468 - val_loss: 2.9005\n",
      "\n",
      "Epoch 00033: val_loss improved from 2.90991 to 2.90047, saving model to best_model.h5\n",
      "Epoch 34/50\n",
      "503/503 [==============================] - 14s 28ms/step - loss: 2.5348 - val_loss: 2.8975\n",
      "\n",
      "Epoch 00034: val_loss improved from 2.90047 to 2.89750, saving model to best_model.h5\n",
      "Epoch 35/50\n",
      "503/503 [==============================] - 14s 28ms/step - loss: 2.5280 - val_loss: 2.8764\n",
      "\n",
      "Epoch 00035: val_loss improved from 2.89750 to 2.87645, saving model to best_model.h5\n",
      "Epoch 36/50\n",
      "503/503 [==============================] - 15s 30ms/step - loss: 2.5124 - val_loss: 2.8818\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 2.87645\n",
      "Epoch 37/50\n",
      "503/503 [==============================] - 14s 28ms/step - loss: 2.5101 - val_loss: 2.8749\n",
      "\n",
      "Epoch 00037: val_loss improved from 2.87645 to 2.87487, saving model to best_model.h5\n",
      "Epoch 38/50\n",
      "503/503 [==============================] - 13s 26ms/step - loss: 2.4927 - val_loss: 2.8737\n",
      "\n",
      "Epoch 00038: val_loss improved from 2.87487 to 2.87374, saving model to best_model.h5\n",
      "Epoch 39/50\n",
      "503/503 [==============================] - 14s 27ms/step - loss: 2.4890 - val_loss: 2.8695\n",
      "\n",
      "Epoch 00039: val_loss improved from 2.87374 to 2.86952, saving model to best_model.h5\n",
      "Epoch 40/50\n",
      "503/503 [==============================] - 15s 30ms/step - loss: 2.4877 - val_loss: 2.8680\n",
      "\n",
      "Epoch 00040: val_loss improved from 2.86952 to 2.86795, saving model to best_model.h5\n",
      "Epoch 41/50\n",
      "503/503 [==============================] - 13s 26ms/step - loss: 2.4826 - val_loss: 2.8637\n",
      "\n",
      "Epoch 00041: val_loss improved from 2.86795 to 2.86372, saving model to best_model.h5\n",
      "Epoch 42/50\n",
      "503/503 [==============================] - 13s 26ms/step - loss: 2.4756 - val_loss: 2.8534\n",
      "\n",
      "Epoch 00042: val_loss improved from 2.86372 to 2.85337, saving model to best_model.h5\n",
      "Epoch 43/50\n",
      "503/503 [==============================] - 13s 26ms/step - loss: 2.4685 - val_loss: 2.8523\n",
      "\n",
      "Epoch 00043: val_loss improved from 2.85337 to 2.85228, saving model to best_model.h5\n",
      "Epoch 44/50\n",
      "503/503 [==============================] - 14s 28ms/step - loss: 2.4574 - val_loss: 2.8518\n",
      "\n",
      "Epoch 00044: val_loss improved from 2.85228 to 2.85185, saving model to best_model.h5\n",
      "Epoch 45/50\n",
      "503/503 [==============================] - 14s 28ms/step - loss: 2.4414 - val_loss: 2.8398\n",
      "\n",
      "Epoch 00045: val_loss improved from 2.85185 to 2.83984, saving model to best_model.h5\n",
      "Epoch 46/50\n",
      "503/503 [==============================] - 13s 26ms/step - loss: 2.4441 - val_loss: 2.8434\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 2.83984\n",
      "Epoch 47/50\n",
      "503/503 [==============================] - 15s 29ms/step - loss: 2.4397 - val_loss: 2.8430\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 2.83984\n",
      "Epoch 48/50\n",
      "503/503 [==============================] - 16s 31ms/step - loss: 2.4309 - val_loss: 2.8292\n",
      "\n",
      "Epoch 00048: val_loss improved from 2.83984 to 2.82918, saving model to best_model.h5\n",
      "Epoch 49/50\n",
      "503/503 [==============================] - 15s 30ms/step - loss: 2.4273 - val_loss: 2.8339\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 2.82918\n",
      "Epoch 50/50\n",
      "503/503 [==============================] - 16s 31ms/step - loss: 2.4304 - val_loss: 2.8303\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 2.82918\n"
     ]
    }
   ],
   "source": [
    "mc=ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True,verbose=1)\n",
    "history = model.fit(np.array(x_tr),np.array(y_tr),batch_size=128,epochs=50, validation_data=(np.array(x_val),np.array(y_val)),verbose=1, callbacks=[mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading best model\n",
    "from keras.models import load_model\n",
    "model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[23, 30, 11, 11, 11, 11, 110, 40, 110, 11, 40, 40, 40, 40, 40, 40, 110, 11, 11, 11, 11, 11, 11, 11, 11, 110, 110, 110, 40, 110, 23, 23, 40, 11, 11, 11, 11, 40, 11, 11, 40, 11, 40, 40, 40, 40, 40, 40, 40, 109, 109, 109, 109, 109, 109, 109, 80, 40, 40, 40, 40, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "ind = np.random.randint(0,len(x_val)-1)\n",
    "\n",
    "random_music = x_val[ind]\n",
    "\n",
    "predictions=[]\n",
    "for i in range(100):\n",
    "\n",
    "    random_music = random_music.reshape(1,no_of_timesteps)\n",
    "\n",
    "    prob  = model.predict(random_music)[0]\n",
    "    y_pred= np.argmax(prob,axis=0)\n",
    "    predictions.append(y_pred)\n",
    "\n",
    "    random_music = np.insert(random_music[0],len(random_music[0]),y_pred)\n",
    "    random_music = random_music[1:]\n",
    "    \n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_int_to_note = dict((number, note_) for number, note_ in enumerate(unique_x)) \n",
    "predicted_notes = [x_int_to_note[i] for i in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_midi(prediction_output):\n",
    "   \n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        \n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                \n",
    "                cn=int(current_note)\n",
    "                new_note = note.Note(cn)\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "                \n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "            \n",
    "        # pattern is a note\n",
    "        else:\n",
    "            \n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 1\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='music.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_midi(predicted_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}